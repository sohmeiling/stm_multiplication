---
title: "data-wrangling_codes"
output: html_document
date: "2023-08-16"
---

# Data wrangling

## Typing task

- Remove all the fast (<0.25s) and slow (> 5s) trials

```{r}
library(tidyverse)

typing_df <- read_csv("consolidated_typing_data.csv", 
                      col_types = cols(group = col_character(),
                                       typedNumber = col_character(),
                                       typingRT = col_double(),
                                       answerCorr = col_double(),
                                       participant = col_character())) %>%
  filter(typingRT >= 0.25 & typingRT <= 5) %>% 
  group_by(participant) %>%
  summarize(median_RT = median(typingRT),
            num_correct_trials = sum(answerCorr == 1, na.rm = TRUE)) %>% 
  filter(num_correct_trials >= 15)


# Save the cleaned data
write_csv(typing_df, "cleaned_typing_data.csv")
  
```

## Multiplication production task

```{r}

# Define column types based on the message
col_types <- cols(
  problem = col_factor(),
  OperandType = col_factor(),
  productType = col_factor(),
  group = col_character(),
  typedAnswer = col_character(),
  multiplyRT = col_double(),
  multiplyCorr = col_double(),
  participant = col_character()
)

mult_df <- read_csv("consolidated_data/consolidated_mult_data.csv", 
                    col_types = col_types) 

mult_df2 <- read_csv("consolidated_data/consolidated_mult_data.csv", 
                    col_types = col_types) %>% 
  filter(multiplyCorr == 1)

# Calculate the trials for each participant
n_trials_mult <- mult_df %>% 
  group_by(participant) %>% 
  summarize(n = n())

rt_extreme <- mult_df %>% 
  filter(multiplyRT <= 10) %>% 
  filter(multiplyRT >= 0.25)

n_accuracy <- mult_df %>% 
  filter(multiplyCorr == 1) %>% 
  group_by(participant) %>% 
  summarize(percentage = n()/60*100)
  

# Save the cleaned data
write_csv(mult_df, "consolidated_data/cleaned_mult-acc_data.csv")
  
```


## Digit span task

```{r}

col_types <- cols(
  digitSpan = col_character(),
  digits_audio = col_character(),
  EgnerDSrt = col_double(),
  EgnerDSscore = col_double(),
  group = col_character(),
  participant = col_character()
)

egner_span_df <- read_csv("consolidated_data/consolidated_digit-span-egner_data.csv", 
                    col_types = col_types) %>% 
  filter(EgnerDSscore == 1) %>% 
  filter(!is.na(digitSpan)) %>% 
  group_by(participant) %>%
  summarize(max_digitspan = max(digitSpan)) %>% 
  mutate(digitspan_type = "Egner")
  
# Save the cleaned data
write_csv(egner_span_df, "consolidated_data/cleaned_digit-span-egner_data.csv") 
```


```{r}

col_types <- cols(
  digitSpanWAIS = col_character(),
  WAISDSresponse = col_character(),
  WAISDSrt = col_double(),
  WAISDSscore = col_double(),
  group = col_character(),
  participant = col_character()
)

wais_span_df <- read_csv("consolidated_data/consolidated_digit-span-wais_data.csv", 
                    col_types = col_types) %>% 
  filter(WAISDSscore == 1) %>% 
  filter(!is.na(digitSpanWAIS)) %>% 
  group_by(participant) %>%
  summarize(max_digitspan = max(digitSpanWAIS)) %>% 
  mutate(digitspan_type = "WAIS")
  
# Save the cleaned data
write_csv(wais_span_df, "consolidated_data/cleaned_digit-span-wais_data.csv") 
```


## Visual Pattern task

```{r}

col_types <- cols(
  vptCorrect = col_character(),
  noOfBlocks = col_character(),
  group = col_character(),
  participant = col_character()
)

vpt_df <- read_csv("consolidated_data/consolidated_vpt_data.csv", 
                    col_types = col_types) %>% 
  filter(vptCorrect == "TRUE") %>%
  group_by(participant) %>%
  slice_tail(n = 3) %>% 
  summarize(mean_blocks = mean(as.numeric(noOfBlocks)))

  
# Save the cleaned data
write_csv(vpt_df, "consolidated_data/cleaned_vpt_data.csv") 
```